import argparse
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
import threading
import os
from collections import deque
from args import parse_args
from debug_utils import (
    print_mediapipe_keypoint_diff,
    save_debug_frame,
    save_first_last_comparison,
    save_first_frame_keypoints,
    save_debug_log,
)

def infer_face_count(df):
    """æ£€æµ‹CSVä¸­faceå…³é”®ç‚¹æ•°é‡ï¼ˆè¿”å›ç‚¹æ•°ï¼‰"""
    max_i = -1
    for col in df.columns:
        if col.startswith('face_') and col.endswith('_x'):
            try:
                idx = int(col.split('_')[1])
                if idx > max_i:
                    max_i = idx
            except Exception:
                pass
    return max_i + 1 if max_i >= 0 else 0

def load_face_keypoints_matrix(df, face_count):
    """ä»CSVåŠ è½½é¢éƒ¨å…³é”®ç‚¹çŸ©é˜µ (n_frames, face_count, 2)ï¼ŒCSV ä¸­å­˜çš„æ˜¯åƒç´ åæ ‡"""
    n = len(df)
    pts = np.full((n, face_count, 2), np.nan, dtype=np.float64)
    for i in range(face_count):
        cx = f'face_{i}_x'
        cy = f'face_{i}_y'
        if cx in df.columns and cy in df.columns:
            pts[:, i, 0] = df[cx].astype(np.float64).values
            pts[:, i, 1] = df[cy].astype(np.float64).values
    return pts

def build_face_triangles(points):
    """ä½¿ç”¨ Delaunay ä¸‰è§’å‰–åˆ†æ„å»ºé¢éƒ¨ä¸‰è§’å½¢åˆ†å‰²"""
    from scipy.spatial import Delaunay
    # è¿‡æ»¤ NaN ç‚¹
    valid_mask = ~np.isnan(points).any(axis=1)
    valid_points = points[valid_mask]
    valid_indices = np.where(valid_mask)[0]
    
    delaunay = Delaunay(valid_points)
    triangles = delaunay.simplices
    
    # å°†ä¸‰è§’å½¢ç´¢å¼•æ˜ å°„å›åŸå§‹ç´¢å¼•
    triangles_mapped = np.zeros_like(triangles)
    for i in range(len(triangles)):
        for j in range(3):
            triangles_mapped[i, j] = valid_indices[triangles[i, j]]
    
    return triangles_mapped

def warp_face_triangles(src_img, src_pts, tgt_pts, triangles):
    """
    ä½¿ç”¨ä¸‰è§’å½¢å˜å½¢ï¼šå¯¹æ¯ä¸ªä¸‰è§’å½¢å†…çš„æ‰€æœ‰åƒç´ åšä»¿å°„å˜æ¢ã€‚
    """
    # CPUç‰ˆæœ¬ï¼ˆåŸæœ‰ä»£ç ï¼‰- ä¿è¯é¢œè‰²æ­£ç¡®
    h, w = src_img.shape[:2]
    warped = src_img.copy()
    mask_accum = np.zeros((h, w), dtype=np.uint8)

    for tri in triangles:
        src_tri = np.asarray(src_pts[tri], dtype=np.float32)
        tgt_tri = np.asarray(tgt_pts[tri], dtype=np.float32)

        if np.isnan(src_tri).any() or np.isnan(tgt_tri).any():
            continue

        M = cv2.getAffineTransform(src_tri, tgt_tri)
        x, y, ww, hh = cv2.boundingRect(tgt_tri)
        if ww <= 0 or hh <= 0:
            continue

        tgt_tri_roi = (tgt_tri - [x, y]).astype(np.int32)
        mask = np.zeros((hh, ww), dtype=np.uint8)
        cv2.fillConvexPoly(mask, tgt_tri_roi, 255)

        warped_full = cv2.warpAffine(src_img, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)
        roi_src = warped_full[y:y+hh, x:x+ww]
        roi_dst = warped[y:y+hh, x:x+ww]
        roi_dst[mask > 0] = roi_src[mask > 0]
        warped[y:y+hh, x:x+ww] = roi_dst
        mask_accum[y:y+hh, x:x+ww][mask > 0] = 255

    warped[mask_accum == 0] = src_img[mask_accum == 0]
    
    return warped

def warp_with_scale(image, src_kps, tgt_kps, warp_target='face', triangles=None):
    """
    ç®€åŒ–æ¥å£ï¼šä½¿ç”¨ä¸‰è§’å½¢å˜å½¢ã€‚
    """
    if warp_target == 'face':
        if triangles is None:
            triangles = build_face_triangles(src_kps)
        return warp_face_triangles(image, src_kps, tgt_kps, triangles)
    return image.copy()

def fill_missing_keypoints(kps, keypoint_count):
    """ä½¿ç”¨çº¿æ€§æ’å€¼å¡«å……ç¼ºå¤±çš„å…³é”®ç‚¹"""
    n_frames, n_kps, _ = kps.shape
    kps_flat = kps.reshape(n_frames, -1)
    df = pd.DataFrame(kps_flat)
    df.interpolate(method='linear', axis=0, inplace=True, limit_direction='both')
    filled_flat = df.to_numpy()
    filled = filled_flat.reshape(n_frames, n_kps, 2)
    if np.isnan(filled).any():
        filled = np.nan_to_num(filled, nan=0.0)
        print("è­¦å‘Šï¼šæ’å€¼åä»æœ‰ NaN å€¼ï¼Œå·²ç”¨ 0 å¡«å……")
    return filled

def compute_frame_diff(src_img, warped_img):
    """è®¡ç®—åŸå›¾ä¸å˜å½¢åå›¾åƒçš„å·®å¼‚"""
    diff = cv2.absdiff(src_img, warped_img)
    mean_diff = np.mean(diff)
    max_diff = np.max(diff)
    return {"mean_diff": float(mean_diff), "max_diff": float(max_diff)}

def generate_frame(idx, tgt_kps, src_img, src_kps, args, triangles=None, log_data=None, log_lock=None):
    """ç”Ÿæˆå˜å½¢å¸§ï¼ˆçº¿ç¨‹å®‰å…¨ç‰ˆæœ¬ï¼‰"""
    if idx == 0:
        if log_data is not None and log_lock is not None:
            with log_lock:
                log_data[str(idx)] = {
                    "frame_id": idx,
                    "diff": {"mean_diff": 0.0, "max_diff": 0.0},
                    "keypoint_points": []
                }
        return idx, src_img.copy()

    frame = warp_with_scale(src_img, src_kps, tgt_kps, args.warp_target, triangles)

    # è®¡ç®—diffï¼ˆçº¿ç¨‹å®‰å…¨çš„æ—¥å¿—æ›´æ–°ï¼‰
    if log_data is not None and log_lock is not None:
        diff_info = compute_frame_diff(src_img, frame)
        with log_lock:
            log_data[str(idx)] = {
                "frame_id": idx,
                "diff": diff_info
            }
            
            # åªåœ¨æ¯ 10 å¸§æ—¶è°ƒç”¨ MediaPipe æ£€æµ‹å…³é”®ç‚¹å·®å¼‚
            if idx % 10 == 0:
                print(f"\n=== å¸§ {idx} ===")
                print(f"å›¾åƒå˜å½¢å·®å¼‚ - å¹³å‡: {diff_info['mean_diff']:.2f}, æœ€å¤§: {diff_info['max_diff']:.2f}")
                print_mediapipe_keypoint_diff(frame, tgt_kps, args.warp_target, log_data, idx)

    return idx, frame

def generate_frame_batch(indices, batch_tgt_kps, src_img, src_kps, args, triangles, log_data_list):
    """æ‰¹é‡ç”Ÿæˆå¸§ - ç›´æ¥ä½¿ç”¨åŸæœ‰çš„å•å¸§å¤„ç†é€»è¾‘"""
    result = []
    
    for idx, tgt_kps in zip(indices, batch_tgt_kps):
        if idx == 0:
            log_data_list.append((str(idx), {
                "frame_id": idx,
                "diff": {"mean_diff": 0.0, "max_diff": 0.0}
            }))
            result.append((idx, src_img.copy()))
        else:
            # ç›´æ¥ä½¿ç”¨åŸæœ‰çš„å•å¸§å¤„ç†å‡½æ•°ï¼Œä¿è¯é¢œè‰²å¤„ç†å®Œå…¨ä¸€è‡´
            frame = warp_with_scale(src_img, src_kps, tgt_kps, args.warp_target, triangles)
            diff_info = compute_frame_diff(src_img, frame)
            log_data_list.append((str(idx), {
                "frame_id": idx,
                "diff": diff_info
            }))
            result.append((idx, frame))
    
    return result

def evaluate_generated_frames(output_dir, n_frames):
    """è¯„ä¼°ç”Ÿæˆçš„å¸§ï¼Œç»Ÿè®¡ç”Ÿæˆçš„å¸§æ•°é‡å’Œæ–‡ä»¶å¤§å°"""
    frame_files = sorted([f for f in os.listdir(output_dir) if f.startswith('frame_') and f.endswith('.png')])
    if len(frame_files) != n_frames:
        print(f"è­¦å‘Šï¼šç”Ÿæˆçš„å¸§æ•°é‡ ({len(frame_files)}) ä¸é¢„æœŸå¸§æ•° ({n_frames}) ä¸ä¸€è‡´")
    total_size = sum(os.path.getsize(os.path.join(output_dir, f)) for f in frame_files)
    print(f"è¯„ä¼°ç»“æœï¼šç”Ÿæˆäº† {len(frame_files)} å¸§ï¼Œæ€»å¤§å° {total_size / 1024:.2f} KB")
    return len(frame_files), total_size

def main():
    args = parse_args()
    src_img = cv2.imread(args.source)
    if src_img is None:
        raise ValueError(f'æ— æ³•è¯»å–æºå›¾åƒ: {args.source}')
    width, height = args.width or src_img.shape[1], args.height or src_img.shape[0]
    src_img = cv2.resize(src_img, (width, height))
    df = pd.read_csv(args.csv)
    keypoint_count = infer_face_count(df)
    kps = load_face_keypoints_matrix(df, keypoint_count)
    src_kps = kps[0]
    filled_kps = fill_missing_keypoints(kps, keypoint_count)
    triangles = build_face_triangles(src_kps)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.join(os.path.dirname(args.output), "generated_frames")
    os.makedirs(output_dir, exist_ok=True)
    print(f"ç”Ÿæˆçš„å¸§å°†ä¿å­˜åœ¨ç›®å½•: {output_dir}")

    # åˆå§‹åŒ–è°ƒè¯•æ—¥å¿—
    log_data = {}
    exceptions = []
    exception_lock = threading.Lock()
    
    total_frames = len(filled_kps)
    batch_size = 10  # ä¸€æ¬¡ç”Ÿæˆ 4 å¸§ï¼ˆåˆ©ç”¨ 4GB æ˜¾å­˜ï¼‰
    
    # ç¬¬ä¸€æ­¥ï¼šæ‰¹é‡ç”Ÿæˆå¸§
    print("\nğŸš€ é˜¶æ®µ 1: æ‰¹é‡ç”Ÿæˆå¸§åˆ°å†…å­˜ï¼ˆæ‰¹å¤§å°=%dï¼‰..." % batch_size)
    frames_data = {}
    log_data_batch = []
    
    gen_pbar = tqdm(total=total_frames, desc="ç”Ÿæˆå¸§")
    for batch_start in range(0, total_frames, batch_size):
        batch_end = min(batch_start + batch_size, total_frames)
        batch_indices = list(range(batch_start, batch_end))
        batch_kps = [filled_kps[i] for i in batch_indices]
        
        try:
            batch_result = generate_frame_batch(
                batch_indices, batch_kps, src_img, src_kps, args, triangles, log_data_batch
            )
            for idx, frame in batch_result:
                frames_data[idx] = frame
        except Exception as e:
            with exception_lock:
                exceptions.append(f"æ‰¹ç”Ÿæˆ {batch_start}-{batch_end} å¼‚å¸¸: {str(e)}")
        
        gen_pbar.update(batch_end - batch_start)
    gen_pbar.close()
    
    # åˆå¹¶æ—¥å¿—
    for key, val in log_data_batch:
        log_data[key] = val
    
    # ç¬¬äºŒæ­¥ï¼šæ¿€è¿›å¹¶è¡Œä¿å­˜ï¼ˆæœ€å¤§ CPU æ ¸å¿ƒï¼‰
    print("\nâš¡ é˜¶æ®µ 2: æ¿€è¿›å¹¶è¡Œä¿å­˜åˆ°ç£ç›˜...")
    
    def save_frame_optimized(idx):
        if idx not in frames_data:
            return
        try:
            frame_path = os.path.join(output_dir, f"frame_{idx:06d}.png")
            cv2.imwrite(frame_path, frames_data[idx], [cv2.IMWRITE_PNG_COMPRESSION, 0])
        except Exception as e:
            with exception_lock:
                exceptions.append(f"ä¿å­˜å¸§ {idx} å¼‚å¸¸: {str(e)}")
    
    num_workers = os.cpu_count() or 16
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        list(tqdm(executor.map(save_frame_optimized, range(total_frames)), 
                 total=total_frames, desc="ä¿å­˜å¸§"))
    
    # ç¬¬ä¸‰æ­¥ï¼šæ¸…ç†å†…å­˜
    print("\nğŸ§¹ æ¸…ç†å†…å­˜...")
    frames_data.clear()
    log_data_batch.clear()
    if torch is not None and CUDA_AVAILABLE:
        torch.cuda.empty_cache()
    print("âœ… å†…å­˜å’Œæ˜¾å­˜å·²é‡Šæ”¾")

    if exceptions:
        print("\nâš ï¸ å¼‚å¸¸:")nâš ï¸ å¼‚å¸¸:")
        for exc in exceptions::
            print(f"  - {exc}")

    save_debug_log(log_data, args)
    evaluate_generated_frames(output_dir, len(filled_kps))rated_frames(output_dir, len(filled_kps))

if __name__ == '__main__':__main__':
    main()